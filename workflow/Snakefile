configfile: "../config/config.yaml"

# Load values from config.yaml
LONGREADS = config["LONGREADS"]
LONGREAD_FILE_TYPE = config["LONGREAD_FILE_TYPE"]
SHORTREADS = config["SHORTREADS"]
SHORTREAD_FILE_TYPE = config["SHORTREAD_FILE_TYPE"]
PREFIX = config["PREFIX"]
REFERENCE_ASSEMBLY = config["REFERENCE_ASSEMBLY"]
REFERENCE_GFF = config["REFERENCE_GFF"]
RNASEQ_IDS = config["RNASEQ_IDS"]
RNASEQ_BAMS = config["RNASEQ_BAMS"]
PROTEIN_SEQUENCES = config["PROTEIN_SEQUENCES"]
HINTS_FILE = config["HINTS_FILE"]
outdir = config["OUTDIR"]

def check_file_type(file_type):
    supported_file_types = {"fa", "fa.gz", "fasta", "fasta.gz", "fq", "fq.gz", "fastq", "fastq.gz"}
    if not any(file_type.lower().endswith(extension) for extension in supported_file_types):
        raise ValueError(f"Invalid file type: {file_type}. Supported types are {', '.join(supported_file_types)}.")
    return file_type.lower()

try:
    file_type = check_file_type(LONGREAD_FILE_TYPE)
except ValueError as error:
    raise WorkflowError(error)

rule all:
    input:
        expand("{outdir}/MultiQC/multiqc_report.html", outdir=outdir, shortreads=SHORTREADS, longread_file_type=LONGREAD_FILE_TYPE, REFERENCE_ASSEMBLY=REFERENCE_ASSEMBLY, prefix=PREFIX),
        "{outdir}/BRAKER/braKER_output.gff3"

if {LONGREADS}/basecalling_summary.tsv:
    rule pycoqc:
        message:
            "Rule {rule} processing"
        output:
            "{outdir}/PycoQC/PycoQC_output.html"
        threads: 1
        resources:
            mem_mb=10000,
            time="0-0:4:0"
        singularity:
            "docker://robegan21/pycoqc:v2.5.2"
        shell:
            f"pycoQC -f {LONGREADS}/basecalling_summary.tsv -o {{output}}"

rule merge_long_reads:
    message:
        "Rule {rule} processing"
    output:
    temp(f"{outdir}/temp_long_reads.{LONGREAD_FILE_TYPE.lower()}")
    threads: 1
    resources:
        mem_mb=2000,
        time="0-0:10:0"
    shell:
        f"cat {LONGREADS}/*.{LONGREAD_FILE_TYPE.lower()} > {{output}}"

rule merge_short_reads:
    message:
        "Rule {rule} processing"
    output:
        forward_short_reads = temp(f"{outdir}/temp_short_reads_1.{SHORTREAD_FILE_TYPE.lower()}"),
        reverse_short_reads = temp(f"{outdir}/temp_short_reads_2.{SHORTREAD_FILE_TYPE.lower()}")
    threads: 1
    resources:
        mem_mb=2000,
        time="0-0:2:0"
    shell:
        f"cat {SHORTREADS}/*1.{SHORTREAD_FILE_TYPE.lower()} > {{output.forward_short_reads}} & cat {SHORTREADS}/*2.{SHORTREAD_FILE_TYPE.lower()} > {{output.reverse_short_reads}}"

rule short_read_trimming:
    message:
        "Rule {rule} processing"
    input:
        forward_short_reads = rules.merge_short_reads.output.forward_short_reads,
        reverse_short_reads = rules.merge_short_reads.output.reverse_short_reads
    output:
        directory("{outdir}/trimmomatic")
    threads: 24
    resources:
        mem_mb=10000,
        time="0-0:45:0"
    singularity:
        "docker://staphb/trimmomatic:0.39"
    script:
        "scripts/trimmomatic.sh"

rule filter_long_reads:
    message:
        "Rule {rule} processing"
    input:
        long_reads=rules.merge_long_reads.output,
        short_reads_dir=rules.short_read_trimming.output
    output:
        "{outdir}/filtlong/filtered_reads_ont.fastq.gz"
    threads: 24
    resources:
        mem_mb=80000,
        time="2-0:0:0"
    singularity:
        "docker://staphb/filtlong:0.2.1"
    shell:
        shell:
    f"filtlong -1 {input.short_reads_dir}/forward_paired_temp_short_reads_1.fastq.gz -2 {input.short_reads_dir}/reverse_paired_temp_short_reads_2.fastq.gz --min_length 1000 --keep_percent 90 --trim --split 1000 {input.long_reads} | gzip > {output}"

rule fastqc_long:
    message:
        "Rule {rule} processing"
    input:
        rules.filter_long_reads.output
    output:
        directory("{outdir}/FastQC_long")
    threads: 12
    resources:
        mem_mb=lambda wildcards, threads, attempt: 1000 * threads * attempt,
        time="0-3:30:0"
    singularity:
        "docker://staphb/fastqc:0.12.1"
    shell:
        f"mkdir -p {{output}} && fastqc -o {{output}} --memory 1024 --svg -t {{threads}} {{input}}"

rule fastqc_short:
    message:
        "Rule {rule} processing"
    input:
        rules.short_read_trimming.output
    output:
        directory("{outdir}/FastQC_short")
    threads: 12
    resources:
        mem_mb=lambda wildcards, threads: 500 * threads,
        time="0-0:12:0"
    singularity:
        "docker://staphb/fastqc:0.12.1"
    shell:
        f"mkdir -p {{output}} && fastqc -o {{output}} --svg -t {{threads}} {{input}}/*_paired_*"

rule assembly:
    message:
        "Rule {rule} processing"
    input:
        rules.filter_long_reads.output
    output:
        directory("{outdir}/flye/")
    threads: 64
    resources:
        mem_mb=400000,
        time="0-22:0:0"
    singularity:
        "docker://staphb/flye:latest"
    shell:
        f"flye --nano-hq {{input}} -o {{output}} -t {{threads}} -i 0 -g 2.8g"

rule polishing:
    message:
        "Rule {rule} processing"
    input:
        rules.filter_long_reads.output,
        rules.short_read_trimming.output,
        rules.assembly.output
    output:
        "{outdir}/NextPolish/genome.nextpolish.fa"
    threads: 64
    resources:
        mem_mb=lambda wildcards, threads: 7000 * threads,
        time="1-0:0:0"
    conda:
        "envs/nextpolish.yaml"
    script:
        "scripts/NextPolish.sh"

rule scaffolding:
    message:
        "Rule {rule} processing"
    input:
        rules.polishing.output
    output:
        directory("{outdir}/RagTag")
    threads: 10
    resources:
        mem_mb=lambda wildcards, threads: 2000 * threads,
        time="0-0:10:0"
    singularity:
        "docker://mcphl/ragtag:latest"
    shell:
        "ragtag.py scaffold {REFERENCE_ASSEMBLY} {input} -t {threads} -o {output} -u"

rule repeat_masking:
    message:
        "Rule {rule} processing"
    input:
        rules.scaffolding.output
    output:
        "{outdir}/RagTag/ragtag.scaffold.fasta.masked"
    threads: 16
    resources:
        mem_mb=lambda wildcards, threads: 2000 * threads,
        time="0-0:10:0"
    singularity:
        "docker://dfam/tetools:latest"
    shell:
        "BuildDatabase -name {prefix} {input}/ragtag.scaffold.fasta && RepeatModeler -database {prefix} -LTRStruct -threads {threads} && RepeatMasker {prefix} -lib library.fa -pa {threads} -cutoff 250 -gff -xsmall"

rule genome_annotation:
    message:
        "Rule {rule} processing"    
    input:
        genome=rules.repeat_masking.output,
        rnaseq_ids= optional(RNASEQ_IDS),
        rnaseq_bam= optional(RNASEQ_BAMS),
        prot_seq= optional(PROTEIN_SEQUENCES),
        hints_file= optional(HINTS_FILE)
    output:
        "{outdir}/BRAKER/braKER_output.gff3"
    params:
        species="bos_taurus",
        threads=8,
        resources={
            'memory': '32G',
            'time': '24h',
            'cpus': 8
        }
    singularity:
        "docker://teambraker/braker3:latest"    
    shell:
        """
        braker3 \
            --genome {input.genome} \
            --species {params.species} \
            --softmasking \
            --cores {params.threads} \
            --output {output} \
            { '--prot_seq ' + input.prot_seq if input.prot_seq else ''} \
            { '--rnaseq_ids ' + input.rnaseq_ids if input.rnaseq_ids else ''} \
            { '--bam ' + input.rnaseq_bam if input.rnaseq_bam else ''} \
            { '--hints_file ' + input.hints_file if input.hints_file else ''}
        """

rule busco:
    message:
        "Rule {rule} processing"
    input:
        rules.rules.repeat_masking.output
    output:
        directory("{outdir}/BUSCO")
    threads: 36
    resources:
        mem_mb=75000,
        time="2-0:0:0"
    singularity:
        "docker://ezlabgva/busco:latest"
    shell:
        "busco -c {threads} -i {input} --auto-lineage-euk --out_path {output} -o busco_out -m genome --download_path ../resources/busco_downloads/ --tar"

rule quast:
    message:
        "Rule {rule} processing"
    input:
        genome=rules.repeat_masking.output,
        long_reads=rules.filter_long_reads.output,
        short_reads_dir=rules.short_read_trimming.output
    output:
        directory("{outdir}/QUAST")
    threads: 56
    resources:
        mem_mb=lambda wildcards, threads: 4000 * threads,
        time="1-12:0:0"
    singularity:
        "docker://staphb/quast:latest"
    shell:
        "quast.py {input.genome} -r {REFERENCE_ASSEMBLY} -o {output} --threads {threads} --nanopore {input.long_reads} --pe1 {input.short_reads_dir}/forward_paired_temp_short_reads_1.fastq.gz --pe2 {input.short_reads_dir}/reverse_paired_temp_short_reads_2.fastq.gz --eukaryote --large --gene-finding --rna-finding --est-ref-size 2770686120 --features {REFERENCE_ASSEMBLY} --k-mer-stats"

rule MultiQC:
    message:
        "Rule {rule} processing"
    input:
        rules.pycoqc.output,
        rules.fastqc_short.output,
        rules.fastqc_long.output,
        rules.busco.output,
        rules.quast.output
    output:
        "{outdir}/MultiQC/multiqc_report.html"
    threads: 1
    resources:
        mem_mb=1000,
        time="0-0:5:0"
    singularity:
        "docker://multiqc/multiqc:latest"
    shell:
        "multiqc {input} -o {outdir}/MultiQC"
