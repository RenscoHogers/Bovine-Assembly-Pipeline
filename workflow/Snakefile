configfile: "../config/config.yaml"

# Load values from config.yaml
LONGREADS = config["LONGREADS"]
LONGREAD_FILE_TYPE = config["LONGREAD_FILE_TYPE"]
SHORTREADS = config["SHORTREADS"]
SHORTREAD_FILE_TYPE = config["SHORTREAD_FILE_TYPE"]
PREFIX = config["PREFIX"]
FASTIX_LOCATION = config["FASTIX_LOCATION"]
REFERENCE_ASSEMBLY = config["REFERENCE_ASSEMBLY"]
REFERENCE_GFF = config["REFERENCE_GFF"]
RNASEQ = config["RNASEQ"]
PROTEIN_SEQUENCES = config["PROTEIN_SEQUENCES"]
BRAKER_CONFIG = config["BRAKER_CONFIG"]
OUTDIR = config["OUTDIR"]

def check_file_type(file_type):
    """
    Validate the file type to ensure it is supported.
    """
    supported_file_types = {
        "fa", "fa.gz", "fasta", "fasta.gz", "fq", "fq.gz", "fastq", "fastq.gz"
    }
    if not any(file_type.lower().endswith(extension) for extension in supported_file_types):
        raise ValueError(f"Invalid file type: {file_type}. Supported types are "
                         f"{', '.join(supported_file_types)}.")
    return file_type.lower()

try:
    file_type = check_file_type(LONGREAD_FILE_TYPE)
except ValueError as error:
    raise WorkflowError(error)

rule all:
    input:
        f"{OUTDIR}/MultiQC/multiqc_report.html",
        f"{OUTDIR}/BRAKER/braker.gff3"

rule pycoQC:
    message:
        "Rule {rule} processing"
    input:
        basecalling_summary = f"{LONGREADS}/basecalling_summary.tsv"
    output:
        "{OUTDIR}/PycoQC/PycoQC_output.html"
    log:
        "{OUTDIR}/PycoQC/pycoqc.out"
    threads: 1
    resources:
        cpus_per_task = 1,
        mem_mb = 7500,
        runtime = "5m"
    container:
        "docker://robegan21/pycoqc:v2.5.2"
    shell:
        """
        if [ -f {input.basecalling_summary} ]; then
            pycoQC -f {input.basecalling_summary} -o {output} >& {log}
        else
            echo "Basecalling summary file not found, skipping pycoqc step."
        fi
        """

rule Merge_long_reads:
    message:
        "Rule {rule} processing"
    output:
        temp(f"{OUTDIR}/temp_long_reads.{LONGREAD_FILE_TYPE.lower()}")
    threads: 1
    resources:
        cpus_per_task = 1,
        mem_mb = 10000,
        runtime = "10m"
    shell:
        f"cat {LONGREADS}/*.{LONGREAD_FILE_TYPE.lower()} > {{output}}"

rule Merge_short_reads:
    message:
        "Rule {rule} processing"
    output:
        forward_short_reads = temp(f"{OUTDIR}/temp_short_reads_1.{SHORTREAD_FILE_TYPE.lower()}"),
        reverse_short_reads = temp(f"{OUTDIR}/temp_short_reads_2.{SHORTREAD_FILE_TYPE.lower()}")
    threads: 1
    resources:
        cpus_per_task = 1,
        mem_mb = 2000,
        runtime = "10m"
    shell:
        f"""
        cat {SHORTREADS}/*1.{SHORTREAD_FILE_TYPE.lower()} > {{output.forward_short_reads}} & \
        cat {SHORTREADS}/*2.{SHORTREAD_FILE_TYPE.lower()} > {{output.reverse_short_reads}}
        """

rule Short_read_trimming:
    message:
        "Rule {rule} processing"
    input:
        forward_short_reads = rules.Merge_short_reads.output.forward_short_reads,
        reverse_short_reads = rules.Merge_short_reads.output.reverse_short_reads
    output:
        directory("{OUTDIR}/trimmomatic")
    threads: 24
    resources:
        cpus_per_task = 48,
        mem_mb = 6000,
        runtime = "90m"
    container:
        "docker://staphb/trimmomatic:0.39"
    script:
        "scripts/trimmomatic.sh"

rule Filter_long_reads:
    message:
        "Rule {rule} processing"
    input:
        long_reads = rules.Merge_long_reads.output,
        short_reads_dir = rules.Short_read_trimming.output
    output:
        "{OUTDIR}/filtlong/filtered_reads_ont.fastq.gz"
    threads: 1
    resources:
        mem_mb = 8000,
        runtime = "10h"
    container:
        "docker://staphb/filtlong:0.2.1"
    shell:
        """
        filtlong --min_length 1000 --min_mean_q 85 {input.long_reads} | gzip > {output}
        """

rule FastQC_long:
    message:
        "Rule {rule} processing"
    input:
        rules.Filter_long_reads.output
    output:
        directory("{OUTDIR}/FastQC_long")
    log:
        "{OUTDIR}/FastQC_long/FastQC_long.out"
    threads: 12
    resources:
        mem_mb = 10000,
        runtime = "2h"
    container:
        "docker://staphb/fastqc:0.12.1"
    shell:
        "mkdir -p {output} && fastqc -o {output} --memory 1024 --svg -t {threads} {input} >& {log}"

rule FastQC_short:
    message:
        "Rule {rule} processing"
    input:
        rules.Short_read_trimming.output
    output:
        directory("{OUTDIR}/FastQC_short")
    log:
        "{OUTDIR}/FastQC_short/FastQC_short.out"
    threads: 12
    resources:
        mem_mb = 4000,
        runtime = "15m"
    container:
        "docker://staphb/fastqc:0.12.1"
    shell:
        "mkdir -p {output} && fastqc -o {output} --svg -t {threads} {input}/*_paired_* >& {log}"

rule Assembly:
    message:
        "Rule {rule} processing"
    input:
        rules.Filter_long_reads.output
    output:
        directory("{OUTDIR}/flye/")
    threads: 64
    resources:
        mem_mb = 300000,
        runtime = "1d"
    container:
        "docker://staphb/flye:latest"
    shell:
        "flye --nano-raw {input} -o {output} -t {threads} -i 0 -g 2.8g"

rule Polishing:
    message:
        "Rule {rule} processing"
    input:
        rules.Filter_long_reads.output,
        rules.Short_read_trimming.output,
        rules.Assembly.output
    output:
        "{OUTDIR}/NextPolish/genome.nextpolish.fa.gz"
    threads: 64
    resources:
        mem_mb = 410000,
        runtime = "3d"
    conda:
        "envs/nextpolish.yaml"
    script:
        "scripts/NextPolish.sh"

rule Scaffolding:
    message:
        "Rule {rule} processing"
    input:
        rules.Polishing.output
    output:
        "{OUTDIR}/RagTag/ragtag.scaffold.fasta"
    log:
        "{OUTDIR}/RagTag/RagTag.out"
    threads: 24
    resources:
        mem_mb = 25000,
        runtime = "5m"
    container:
        "docker://mcphl/ragtag:latest"
    shell:
        """
        ragtag.py scaffold {REFERENCE_ASSEMBLY} {input} -t {threads} -o {OUTDIR}/RagTag/ -u >& {log}
        """

rule PanSN_spec_compliance:
    message:
        "Rule {rule} processing"
    input:
        rules.Scaffolding.output
    output:
        "{OUTDIR}/Genome/scaffolded_genome.fasta"
    threads: 1
    resources:
        mem_mb = 10000,
        runtime = "2m"
    shell:
        """
        {FASTIX_LOCATION} -p "{PREFIX}#1#" {input} > {output}
        """

rule Repeat_masking:
    message:
        "Rule {rule} processing"
    input:
        rules.PanSN_spec_compliance.output
    output:
        "{OUTDIR}/Genome/scaffolded_genome.fasta.masked"
    log:
        "{OUTDIR}/Genome/Repeat_masking.out"
    threads: 32
    resources:
        mem_mb = 50000,
        runtime = "3d"
    container:
        "docker://dfam/tetools:latest"
    params:
        prefix = PREFIX
    shell:
        """
        cd {OUTDIR}/Genome && \
        BuildDatabase -name {params.prefix} {input} && \
        RepeatModeler -database {params.prefix} -LTRStruct -threads {threads} && \
        RepeatMasker -lib {params.prefix}-families.fa -pa {threads} -cutoff 250 -gff -xsmall {input} \
        >& {log}
        """

rule Genome_annotation:
    message:
        "Rule {rule} processing"
    input:
        genome = rules.Repeat_masking.output,
        prot_seq = PROTEIN_SEQUENCES,
    output:
        "{OUTDIR}/BRAKER/braker.gff3"
    log:
        "{OUTDIR}/BRAKER/BRAKER.out"
    threads: 8
    resources:
        mem_mb = 32000,
        runtime = "7d"
    params:
        species="bos_taurus"
    container:
        "docker://teambraker/braker3:latest"
    shell:
        """
            braker.pl \
            --genome {input.genome} \
            --species {params.species} \
            --prot_seq {input.prot_seq} \
            --threads={threads} \
            --rnaseq_sets_ids {RNASEQ} \
            --gff3 \
            --workingdir={OUTDIR}/BRAKER/ \
            --useexisting \
            --AUGUSTUS_CONFIG_PATH={BRAKER_CONFIG}
        """

rule BUSCO:
    message:
        "Rule {rule} processing"
    input:
        genome = rules.Repeat_masking.output
    output:
        directory("{OUTDIR}/BUSCO")
    log:
        "{OUTDIR}/BUSCO/BUSCO.out"
    threads: 36
    resources:
        mem_mb = 60000,
        runtime = "1h"
    conda:
        "envs/busco.yaml"
    shell:
        """
        busco -c {threads} -i {input.genome} --auto-lineage-euk --out_path {OUTDIR} -o BUSCO \
        -m genome --download_path ../resources/busco_downloads/ --tar -f
        """

rule QUAST:
    message:
        "Rule {rule} processing"
    input:
        genome = rules.Repeat_masking.output,
        long_reads = rules.Filter_long_reads.output,
        short_reads_dir = rules.Short_read_trimming.output
    output:
        directory("{OUTDIR}/QUAST")
    log:
        "{OUTDIR}/QUAST/QUAST.out"
    threads: 56
    resources:
        mem_mb = 350000,
        runtime = "50h"
    container:
        "docker://staphb/quast:latest"
    shell:
        """
        quast.py {input.genome} -r {REFERENCE_ASSEMBLY} -o {output} --threads {threads} --nanopore {input.long_reads} \
        --pe1 {input.short_reads_dir}/forward_paired_temp_short_reads_1.fastq.gz \
        --pe2 {input.short_reads_dir}/reverse_paired_temp_short_reads_2.fastq.gz \
        --eukaryote --large --gene-finding --rna-finding --est-ref-size 2770686120 \
        --features {REFERENCE_GFF} --k-mer-stats \
        >& {log}
        """

rule MultiQC:
    message:
        "Rule {rule} processing"
    input:
        rules.pycoQC.output,
        rules.FastQC_short.output,
        rules.FastQC_long.output,
        rules.BUSCO.output,
        rules.QUAST.output
    output:
        "{OUTDIR}/MultiQC/multiqc_report.html"
    log:
        "{OUTDIR}/MultiQC/MultiQC.out"
    threads: 1
    resources:
        mem_mb = 1000,
        runtime = "5m"
    container:
        "docker://multiqc/multiqc:latest"
    shell:
        "multiqc {input} -o {OUTDIR}/MultiQC >& {log}"
