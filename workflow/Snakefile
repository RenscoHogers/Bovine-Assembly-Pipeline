configfile: "../config/config.yaml"

# Load values from config.yaml
LONGREADS = config["LONGREADS"]
LONGREAD_FILE_TYPE = config["LONGREAD_FILE_TYPE"]
SHORTREADS = config["SHORTREADS"]
SHORTREAD_FILE_TYPE = config["SHORTREAD_FILE_TYPE"]
PREFIX = config["PREFIX"]
REFERENCE_ASSEMBLY = config["REFERENCE_ASSEMBLY"]
REFERENCE_GFF = config["REFERENCE_GFF"]
RNASEQ = config["RNASEQ"]
PROTEIN_SEQUENCES = config["PROTEIN_SEQUENCES"]
OUTDIR = config["OUTDIR"]

def check_file_type(file_type):
    """
    Validate the file type to ensure it is supported.
    """
    supported_file_types = {
        "fa", "fa.gz", "fasta", "fasta.gz", "fq", "fq.gz", "fastq", "fastq.gz"
    }
    if not any(file_type.lower().endswith(extension) for extension in supported_file_types):
        raise ValueError(f"Invalid file type: {file_type}. Supported types are "
                         f"{', '.join(supported_file_types)}.")
    return file_type.lower()

try:
    file_type = check_file_type(LONGREAD_FILE_TYPE)
except ValueError as error:
    raise WorkflowError(error)

rule all:
    input:
        f"{OUTDIR}/MultiQC/multiqc_report.html",
        f"{OUTDIR}/BRAKER/braKER_output.gff3"

rule pycoQC:
    message:
        "Rule {rule} processing"
    input:
        basecalling_summary = f"{LONGREADS}/basecalling_summary.tsv"
    output:
        "{OUTDIR}/PycoQC/PycoQC_output.html"
    log:
        "{OUTDIR}/PycoQC/pycoqc.out"
    threads: 1
    resources:
        cpus_per_task = 1,
        mem_mb = 10000,
        runtime = "4m"
    container:
        "docker://robegan21/pycoqc:v2.5.2"
    shell:
        """
        if [ -f {input.basecalling_summary} ]; then
            pycoQC -f {input.basecalling_summary} -o {output} >& {log}
        else
            echo "Basecalling summary file not found, skipping pycoqc step."
        fi
        """

rule Merge_long_reads:
    message:
        "Rule {rule} processing"
    output:
        temp(f"{OUTDIR}/temp_long_reads.{LONGREAD_FILE_TYPE.lower()}")
    threads: 1
    resources:
        cpus_per_task = 1,
        mem_mb = 10000,
        runtime = "10m"
    shell:
        f"cat {LONGREADS}/*.{LONGREAD_FILE_TYPE.lower()} > {{output}}"

rule Merge_short_reads:
    message:
        "Rule {rule} processing"
    output:
        forward_short_reads = temp(f"{OUTDIR}/temp_short_reads_1.{SHORTREAD_FILE_TYPE.lower()}"),
        reverse_short_reads = temp(f"{OUTDIR}/temp_short_reads_2.{SHORTREAD_FILE_TYPE.lower()}")
    threads: 1
    resources:
        cpus_per_task = 1,
        mem_mb = 10000,
        runtime = "2m"
    shell:
        f"""
        cat {SHORTREADS}/*1.{SHORTREAD_FILE_TYPE.lower()} > {{output.forward_short_reads}} & \
        cat {SHORTREADS}/*2.{SHORTREAD_FILE_TYPE.lower()} > {{output.reverse_short_reads}}
        """

rule Short_read_trimming:
    message:
        "Rule {rule} processing"
    input:
        forward_short_reads = rules.Merge_short_reads.output.forward_short_reads,
        reverse_short_reads = rules.Merge_short_reads.output.reverse_short_reads
    output:
        directory("{OUTDIR}/trimmomatic")
    threads: 24
    resources:
        cpus_per_task = 24,
        mem_mb = 10000,
        runtime = "1h"
    container:
        "docker://staphb/trimmomatic:0.39"
    script:
        "scripts/trimmomatic.sh"

rule Filter_long_reads:
    message:
        "Rule {rule} processing"
    input:
        long_reads = rules.Merge_long_reads.output,
        short_reads_dir = rules.Short_read_trimming.output
    output:
        "{OUTDIR}/filtlong/filtered_reads_ont.fastq.gz"
    threads: 1
    resources:
        mem_mb = 80000,
        runtime = "10h"
    container:
        "docker://staphb/filtlong:0.2.1"
    shell:
        """
        filtlong --min_length 1000 --min_mean_q 95 {input.long_reads} | gzip > {output}
        """

rule FastQC_long:
    message:
        "Rule {rule} processing"
    input:
        rules.Filter_long_reads.output
    output:
        directory("{OUTDIR}/FastQC_long")
    log:
        "{OUTDIR}/FastQC_long/FastQC_long.out"
    threads: 12
    resources:
        mem_mb = lambda wildcards, threads, attempt: 1000 * threads * attempt,
        runtime = "2h"
    container:
        "docker://staphb/fastqc:0.12.1"
    shell:
        "mkdir -p {output} && fastqc -o {output} --memory 1024 --svg -t {threads} {input} >& {log}"

rule FastQC_short:
    message:
        "Rule {rule} processing"
    input:
        rules.Short_read_trimming.output
    output:
        directory("{OUTDIR}/FastQC_short")
    log:
        "{OUTDIR}/FastQC_short/FastQC_short.out"
    threads: 12
    resources:
        mem_mb = lambda wildcards, threads: 500 * threads,
        runtime = "12m"
    container:
        "docker://staphb/fastqc:0.12.1"
    shell:
        "mkdir -p {output} && fastqc -o {output} --svg -t {threads} {input}/*_paired_* >& {log}"

rule Assembly:
    message:
        "Rule {rule} processing"
    input:
        rules.Filter_long_reads.output
    output:
        directory("{OUTDIR}/flye/")
    threads: 64
    resources:
        mem_mb = 400000,
        runtime = "3d"
    container:
        "docker://staphb/flye:latest"
    shell:
        "flye --nano-hq {input} -o {output} -t {threads} -i 0 -g 2.8g"

rule Polishing:
    message:
        "Rule {rule} processing"
    input:
        rules.Filter_long_reads.output,
        rules.Short_read_trimming.output,
        rules.Assembly.output
    output:
        "{OUTDIR}/NextPolish/genome.nextpolish.fa"
    log:
        "{OUTDIR}/NextPolish/NextPolish.out"
    threads: 64
    resources:
        mem_mb = lambda wildcards, threads: 7000 * threads,
        runtime = "1d"
    conda:
        "envs/nextpolish.yaml"
    script:
        "scripts/NextPolish.sh"

rule Scaffolding:
    message:
        "Rule {rule} processing"
    input:
        rules.Polishing.output
    output:
        "{OUTDIR}/RagTag/ragtag.scaffold.fasta"
    log:
        "{OUTDIR}/RagTag/RagTag.out"
    threads: 10
    resources:
        mem_mb = lambda wildcards, threads: 2000 * threads,
        runtime = "10m"
    container:
        "docker://mcphl/ragtag:latest"
    shell:
        "ragtag.py scaffold {REFERENCE_ASSEMBLY} {input} -t {threads} -o {OUTDIR}/RagTag/ -u >& {log}"

rule Repeat_masking:
    message:
        "Rule {rule} processing"
    input:
        scaffolded_genome = "{OUTDIR}/RagTag/ragtag.scaffold.fasta"
    output:
        "{OUTDIR}/RagTag/ragtag.scaffold.fasta.masked"
    log:
        "{OUTDIR}/RagTag/Repeat_masking.out"
    threads: 16
    resources:
        mem_mb = lambda wildcards, threads: 2000 * threads,
        runtime = "7d"
    container:
        "docker://dfam/tetools:latest"
    shell:
        """
        cd {OUTDIR}/RagTag && \
        BuildDatabase -name {PREFIX} {input.scaffolded_genome} && \
        RepeatModeler -database {PREFIX} -LTRStruct -threads {threads} && \
        RepeatMasker -lib {PREFIX}-families.fa -pa {threads} -cutoff 250 -gff -xsmall {input.scaffolded_genome} \
        >& {log}
        """

rule Genome_annotation:
    message:
        "Rule {rule} processing"
    input:
        genome = rules.Repeat_masking.output,
        prot_seq = PROTEIN_SEQUENCES,
        rna_seq = RNASEQ
    output:
        "{OUTDIR}/BRAKER/braKER_output.gff3"
    log:
        "{OUTDIR}/BRAKER/BRAKER.out"
    params:
        species="bos_taurus",
        threads=8,
        resources={
            'memory': '32G',
            'runtime': '24h',
            'cpus': 8
        }
    container:
        "docker://teambraker/braker3:latest"
    shell:
        """
            braker3 \
            --genome {input.genome} \
            --species {params.species} \
            --prot_seq {input.prot_seq} \
            --softmasking \
            --cores {params.threads} \
            --output {output} \
            --rnaseq_ids {input.rna_seq} \
            >& {log}
        """

rule BUSCO:
    message:
        "Rule {rule} processing"
    input:
        genome = rules.Repeat_masking.output
    output:
        directory("{OUTDIR}/BUSCO")
    log:
        "{OUTDIR}/BUSCO/BUSCO.out"
    threads: 36
    resources:
        mem_mb = 75000,
        runtime = "2d"
    container:
        "docker://ezlabgva/busco:v5.8.2_cv1"
    shell:
        """
        busco -c {threads} -i {input.genome} --auto-lineage-euk --out_path {output} -o busco_out \
        --m genome --download_path ../resources/busco_downloads/ --tar >& {log}
        """

rule QUAST:
    message:
        "Rule {rule} processing"
    input:
        genome = rules.Repeat_masking.output,
        long_reads = rules.Filter_long_reads.output,
        short_reads_dir = rules.Short_read_trimming.output
    output:
        directory("{OUTDIR}/QUAST")
    log:
        "{OUTDIR}/QUAST/QUAST.out"
    threads: 56
    resources:
        mem_mb = lambda wildcards, threads: 4000 * threads,
        runtime = "36h"
    container:
        "docker://staphb/quast:latest"
    shell:
        """
        quast.py {input.genome} -r {REFERENCE_ASSEMBLY} -o {output} --threads {threads} --nanopore {input.long_reads} \
        --pe1 {input.short_reads_dir}/forward_paired_temp_short_reads_1.fastq.gz \
        --pe2 {input.short_reads_dir}/reverse_paired_temp_short_reads_2.fastq.gz \
        --eukaryote --large --gene-finding --rna-finding --est-ref-size 2770686120 \
        --features {REFERENCE_ASSEMBLY} --k-mer-stats >& {log}
        """

rule MultiQC:
    message:
        "Rule {rule} processing"
    input:
        rules.pycoQC.output,
        rules.FastQC_short.output,
        rules.FastQC_long.output,
        rules.BUSCO.output,
        rules.QUAST.output
    output:
        "{OUTDIR}/MultiQC/multiqc_report.html"
    log:
        "{OUTDIR}/MultiQC/MultiQC.out"
    threads: 1
    resources:
        mem_mb = 1000,
        runtime = "5m"
    container:
        "docker://multiqc/multiqc:latest"
    shell:
        "multiqc {input} -o {OUTDIR}/MultiQC >& {log}"
